{"path":"Alte semester/Ethics_in_Information_Systems_and_Design_Science_Research_Five_P.pdf","text":"This is an electronic reprint of the original article. This reprint may differ from the original in pagination and typographic detail. Powered by TCPDF (www.tcpdf.org) This material is protected by copyright and other intellectual property rights, and duplication or sale of all or part of any of the repository collections is not permitted, except that material may be duplicated by you for your research use or educational purposes in electronic or print form. You must obtain permission for any other use. Electronic or print copies may not be offered, whether for sale or otherwise to anyone who is not an authorised user. Herwix, Alexander; Haj-Bolouri, Amir; Rossi, Matti; Tremblay, Monica Chiarini; Purao, Sandeep; Gregor, Shirley Ethics in Information Systems and Design Science Research Published in: Communications of the association for information systems DOI: 10.17705/1CAIS.05028 Published: 01/01/2022 Document Version Publisher's PDF, also known as Version of record Please cite the original version: Herwix, A., Haj-Bolouri, A., Rossi, M., Tremblay, M. C., Purao, S., & Gregor, S. (2022). Ethics in Information Systems and Design Science Research: Five Perspectives. Communications of the association for information systems, 50(1), 589-616. Article 34. https://doi.org/10.17705/1CAIS.05028 Communications of the Association for Information Systems Communications of the Association for Information Systems Volume 50 Article 34 6-16-2022 Ethics in Information Systems and Design Science Research: Five Ethics in Information Systems and Design Science Research: Five Perspectives Perspectives Alexander Herwix Cologne Institute for Information Systems, University of Cologne, Germany Amir Haj-Bolouri Department of Informatics, University West, Sweden Matti Rossi School of Economics, Aalto University, Finland Monica Chiarini Tremblay Raymond A. Mason School of Business, William & Mary, USA Sandeep Purao College of Business, Bentley University, USA See next page for additional authors Follow this and additional works at: https://aisel.aisnet.org/cais Recommended Citation Recommended Citation Herwix, A., Haj-Bolouri, A., Rossi, M., Tremblay, M. C., Purao, S., & Gregor, S. (2022). Ethics in Information Systems and Design Science Research: Five Perspectives. Communications of the Association for Information Systems, 50, pp-pp. https://doi.org/10.17705/1CAIS.05028 This material is brought to you by the AIS Journals at AIS Electronic Library (AISeL). It has been accepted for inclusion in Communications of the Association for Information Systems by an authorized administrator of AIS Electronic Library (AISeL). For more information, please contact elibrary@aisnet.org. Ethics in Information Systems and Design Science Research: Five Perspectives Ethics in Information Systems and Design Science Research: Five Perspectives Authors Authors Alexander Herwix, Amir Haj-Bolouri, Matti Rossi, Monica Chiarini Tremblay, Sandeep Purao, and Shirley Gregor This reports is available in Communications of the Association for Information Systems: https://aisel.aisnet.org/cais/ vol50/iss1/34 C ommunications of the A I S ssociation for nformation ystems Panel Report DOI: 10.17705/1CAIS.05028 ISSN: 1529-3181 Volume 50 Paper 28 pp. 589 – 616 June 2022 Ethics in Information Systems and Design Science Research: Five Perspectives Alexander Herwix Cologne Institute for Information Systems, University of Cologne, Germany Amir Haj-Bolouri Department of Informatics, University West, Sweden Matti Rossi School of Economics, Aalto University, Finland Monica Chiarini Tremblay Raymond A. Mason School of Business, William & Mary, USA Sandeep Purao College of Business, Bentley University, USA Shirley Gregor College of Business & Economics, Australian National University, Australia Abstract: While ethics are recognized as an integral part of information systems (IS) research, many questions about the role of ethics in research practice remain unanswered. Our report responds to this emerging set of concerns with a broad and integrative account of five perspectives on ethics in IS research and design science research (DSR) in particular. Our report is informed by a broad literature review, a panel discussion at DESRIST 2020, and substantial personal experience from wrestling with ethical considerations in the field. The report provides a comprehensive discussion of prevailing perspectives on ethics and the implications for IS research. Together, we hope the report will inspire more ethics-conscious and responsible IS research. Keywords: Ethics, Information Systems Field, Design Science Research, Panel Report. This manuscript underwent editorial review. It was received 04/30/2021 and was with the authors for six months for one revision. Christoph Peters served as Associate Editor. Communications of the Association for Information Systems 590 Volume 50 10.17705/1CAIS.05028 Paper 28 1 Introduction An ongoing digital transformation (Vial, 2019) and emerging technological capabilities have far reaching implications for all facets of societies, and, therefore, raise ethical concerns about how we should deal with such developments (European Group on Ethics in Science and New Technologies, 2018). In an interview van den Hoven described the role of ethics in information systems (IS) (Maedche, 2017, p. 298): Every design, artifact, system is shaped by the values, ideas and world views of the designer and builder. That applies to architecture, software engineering, product design, synthetic biology, material science and civil engineering. A design is a consolidated set of choices made by designers, developers and engineers. Via their designs for systems and artifacts they come to have an incredible impact on the lives of others […]. These are all formidable shapers of the world we inhabit and in which we acquire our beliefs, decide and act, expect, feel, and hope. […] In order to shape these environments in which we will function as moral beings in a responsible way, we need to express or ‘‘design in’’ our shared moral values. Values should therefore be seen as a sort of supra- or non-functional requirements for which we can and ought to design. It will become more and more important in the future to be able to design systematically for moral, legal and social requirements. Given this overt importance of values and ethics for understanding, managing, and designing digital systems, it is clear that ethics—the study of what is right and wrong (“Ethics,” n.d.) in terms of “a set of personal or social standards for good or bad behavior and character” (“Morality,” n.d.)—should be an important consideration for all IS scholars (Mingers & Walsham, 2010; Paradice et al., 2018; Porra, 2001; Stahl, 2012b; Walsham, 1996, 2012). Moreover, ethical considerations and questions are especially prominent for scholars engaged in design science research (DSR) because they aim to change the world by solving real world problems (Hevner et al., 2004; Purao, 2013; Walsham, 2012). In DSR, scholars are explicitly engaged in ethical questions throughout the research lifecycle (e.g., Benke et al., 2020; Herwix & Haj-Bolouri, 2020; Myers & Venable, 2014; Stahl et al., 2011). For instance, which problems should we prioritize given constraints on available resources (Herwix & Haj-Bolouri, 2021, 2020; Purao, 2021)? How can a DSR project be carried out in an ethical manner (e.g., Benke et al., 2020; Myers & Venable, 2014)? What are appropriate techniques for integrating ethical considerations into the design of solutions (e.g., Friedman et al., 2008; Manders-Huits, 2011; Van Den Hoven, 2007)? How can evaluations be leveraged to enhance the ethical value of research projects (e.g., Stahl et al., 2011)? Questions such as these are critical for design science researchers, and, in our opinion, rarely addressed. With this report, we wish to raise awareness of these concerns, and contribute to the nascent stream of research on engaging with ethics in IS research. Our effort in this report is to develop a comprehensive discussion of ethical considerations for IS research. In particular, our report complements studies on specific aspects or dimensions of ethics in IS research with an overarching discussion informed by five intersecting perspectives (see Figure 1): 1. the Philosophy perspective concerned with the fundamental questions at the core of ethics, 2. the Design perspective concerned with the ethics of design and technology, 3. the Science perspective concerned with ethics in the realm of science, 4. the IS Practice perspective concerned with ethics as applied in IS practice, and 5. the Panelists perspectives concerned with the unique challenges of ethics in DSR practice. 591 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 Figure 1. Five Perspectives on Ethics in IS and DSR. Our exploration of these perspectives is inspired by a panel discussion at the International Conference on Design Science Research in Information Systems and Technology (DESRIST 2020) which brought together four eminent DSR scholars: Matti Rossi, Monica Chiarini Tremblay, Sandeep Purao, and Shirley Gregor. Following the panel discussion with a focus on DSR, we conducted a broad review of ethics that elaborated on and substantiated the concerns discussed by the panelists as well as expanded their scope beyond DSR. The resulting report should be of interest to all IS researchers and not just those interested in DSR. The rest of the paper is organized as follows. Section 2 presents a broad overview of ethics in philosophy along the three major areas of research: metaethics, normative ethics, and applied ethics. In section 3, we discuss the role of ethics in design exploring the themes of ethics-conscious design, technological risks and unintended consequences, and responsibility in technology design. Section 4 reviews some major developments of ethics in science. In section 5, we derive and discuss challenges for ethics in IS practice based on extant literature and the author's professional experience. The panelists’ personal views on ethics are presented in section 6. In Section 7 we integrate the discussion of the preceding perspectives and synthesize a set of recommendations to advance the IS field. We conclude in section 8 by offering a call for action. 2 Ethics in Philosophy As Singer (2019) explains, ethics is a branch of philosophy focused on understanding and justifying concepts of right and wrong as well as good and bad behavior. It is closely linked to the branch of aesthetics—the study of beauty and taste—as both are concerned with axiology—the study of values. The question of how to behave is fundamental to human life in social groups. Thus, it is not surprising that the origin of ethics can be traced back to ancient times with many ethical theories and perspectives evolving over time. Today, the study of ethics is grouped into three major areas of research:  Metaethics, focused on studying the nature, scope, and meaning of moral judgment,  Normative ethics, focused on studying how one ought to be and act in general, and  Applied ethics, focused on studying how to act in a specific situation and circumstance. Discussing these streams of research in depth is well beyond the scope of this paper. In the following, we provide an overview of important considerations that scholars have discussed in each. For a more comprehensive introduction the reader is referred to the excellent summary of the field of ethics by Singer (2019). A more targeted reflection of how ethics may be related to IS research in particular can be found in Stahl (2012b). Communications of the Association for Information Systems 592 Volume 50 10.17705/1CAIS.05028 Paper 28 2.1 Metaethics Metaethics is the branch of ethics concerned with questions about the nature, scope, and meaning of moral judgment. Here, the issues and questions that scholars work on are abstract and a step removed from substantive debates. Metaethics investigates the assumptions and commitments that are reflected in such debates. Thus, it is generally thought to provide a neutral background against which competing moral views can be examined and evaluated (Sayre-McCord, 2014). In the following, we summarize key metaethical positions regarding the semantics of moral discourse, the ontology of moral properties, the psychology of how morality affects us as embodied human agents, and the epistemology of how we come to know moral values (DeLapp, n.d.). Understanding and locating oneself in relation to these positions is an important prerequisite for a serious and rigorous engagement with ethics. For instance, metaethical positions may have strong implications for how to approach ethical discourse. More elaborate introductions to metaethics can be found in Sayre-McCord (2014) and DeLapp (n.d.). 2.1.1 Semantic Issues in Metaethics: Cognitivism vs. Non-Cognitivism One of the major semantic issues in metaethics is the question of what exactly people mean when they make moral judgements. Two broad positions can be distinguished (DeLapp, n.d.; Sayre-McCord, 2014):  Cognitivism holds that we are expressing beliefs or making claims that can be either true or false;  Non-Cognitivism holds that we are doing something else (e.g., taking a stand, expressing an emotion, prescribing an action, etc.) which lacks “truth-apt” cognitive content (i.e., it cannot be true or false). Needless to say, there are interesting arguments for and against both of these positions that go beyond the scope of this paper (e.g., DeLapp, n.d.; Sayre-McCord, 2014). However, we can outline a common challenge that both cognitivism and non-cognitivism face (Sayre-McCord, 2014). Each perspective must account for the observation that moral thought and talk are both (a) distinct (e.g., many people would agree that the moral value of an action cannot be observed in the same way that spatial-temporal objects can) but also (b) significantly continuous with non-moral thought and talk (e.g., moral statements are often phrased in a way that is similar to non-moral “truth-apt” statements). Here and in general, cognitivism more easily accommodates the continuity between moral and non-moral thought and talk but struggles to appreciate the distinctive nature of moral thought and talk. On the other hand, non-cognitivism more easily recognizes the distinctive nature of moral thought and talk but is more challenged to reconcile the continuity. 2.1.2 Ontological Issues in Metaethics: Moral Realism vs. Moral Relativism Metaethical positions may be distinguished in terms of the ontological status that they ascribe to moral values. Two general positions are often distinguished (DeLapp, n.d.; Sayre-McCord, 2014):  Moral realism (also known as objectivism) holds that moral values are “real” or “objective” in that they exist independently of our beliefs or evidence about them;  Moral relativism (also known as subjectivism) holds that moral values are created by individuals or cultures and are, thus, not belief-independent facts that exist “out there”. Moral realism is often defended in an effort to establish universal moral truths that exist irrespective of what any individual or culture might think of them. For instance, one might argue if moral truths are not “objective”, does ethics not become arbitrary? However, even within realist positions there is disagreement about what moral values actually are if they are independent from human belief or culture (DeLapp, n.d.). Moral relativism rejects the idea of moral values as “real” or “objective” in the sense of being independent from belief or culture and maintains that morality is fundamentally anthropocentric. It argues that moral values are created by subjective perspectives and needs on individual or cultural levels and cannot be true or false in a general sense. A relativistic view is often justified based on psychological, epistemological or anthropological considerations (DeLapp, n.d.). For instance, anthropologists have suggested that morality may have emerged from the need for social coordination (Roes, 2003) which is sometimes counted as evidence supporting moral relativism. We note that the question of moral realism vs. moral relativism is orthogonal to the semantic question of cognitivism vs. non-cognitivism. In particular, it is possible to be a moral relativist and cognitivist at the 593 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 same time by maintaining that moral language is systematically false (also known as “error theory”; DeLapp, n.d.). 2.1.3 Psychological Issues in Metaethics: Internalism vs. Externalism An important psychological issue within metaethics is the question of whether there is an inherent motivation for being moral for its own sake or if other persuasive reasons are needed to act morally. Two general positions can be distinguished (DeLapp, n.d.; Sayre-McCord, 2014; Singer, 2019):  Internalism is the position that a moral judgment already implies a psychological motivation to act;  Externalism is the position that an additional desire is needed to motivate moral behavior. Internalism is represented, for example, in the views of Socrates or Aristotle who held that developing one’s own morality in the form of virtue was at the core of being human. Externalism is often concerned with the apparent conflict or compatibility between morality and self-interest. For instance, while it has been argued that acting morally is generally in the long-term interest of an individual, there may always be a temptation to behave immorally in any particular situation if self-interest and morality conflict. A question that is often asked in this context is: “Is it rational to be moral?” Answers diverge and indicate that it may be rational to be, both, immoral and moral given particular assumptions and circumstances. 2.1.4 Epistemological Issues in Metaethics: Moral Particularism vs. Moral Generalism Metaethics is also concerned with moral epistemology and the nature and process of making moral judgments. A particular issue in this context concerns the scope of moral judgments. Here, two general positions can be distinguished (Dancy, 2017):  Moral particularism holds that each situation is unique and should be evaluated on its own terms;  Moral generalism holds that moral judgements must depend on general moral principles. The defining difference between a moral particularist and a moral generalist position concerns the use of moral principles. Moral particularism suggests that moral principles may not always be right and should therefore not be seen as the ultimate arbiter of moral judgements. In effect, each situation should be carefully evaluated on its own terms with due recognition of the present particularities. Moral principles may be informative to consider but should not predetermine the moral judgment. In contrast, moral generalism suggests that moral judgments must to some degree depend on moral principles to ensure the rational application of morality. For instance, it could be argued that without general moral principles inconsistent moral judgements would arise over time. 2.2 Normative Ethics Normative ethics is concerned with setting standards and norms for conduct on a general level. Thus, it engages with general theories of moral behavior such as consequentialism, deontology, or virtue ethics. The development of normative ethics has been a core focus of Western moral philosophers since ancient times and continues to attract attention. A general distinction that can be made is between deontic theories and virtue (also known as aretaic) theories (Alexander & Moore, 2021). Whereas deontic theories are concerned with guidance and evaluation in relation to choices (e.g., acts, intentions), virtue theories focus on what kind of persons we are and should be. As it stands, there seems to be no dominant theory of normative ethics with surveys of philosophers indicating that belief in consequentialism, deontology, virtue ethics, or other theories is almost evenly distributed (Bourget & Chalmers, 2014). 2.2.1 Consequentialism Consequentialism denotes the broad position that normative properties depend only on consequences. It is generally informed by the intuition that what counts in this world are the effects that things or actions will have from the present to the future as we cannot change the past. In normative ethics in particular, consequentialism holds that the morality of a choice (e.g., an act or an intention) depends only on the consequences of that choice. Thus, consequentialists must make explicit what makes certain consequences better than others—they must state what is intrinsically of (dis-)value or, put differently, characterize “the Good” and “the Bad.” Generally, those choices that maximize the Good and minimize the Bad are then the morally right ones to make (Sinnott-Armstrong, 2019). Communications of the Association for Information Systems 594 Volume 50 10.17705/1CAIS.05028 Paper 28 Importantly, when taken as defined above, consequentialism is not a very precise position but more like a broad class of more specific moral theories (Sinnott-Armstrong, 2019). The most prominent example is classic utilitarianism which holds that an act is morally right if and only if that act maximizes hedonic value (i.e., the Good is understood in terms of pleasure and the Bad in terms of pain) so that the total amount of pleasure for all minus the total amount of pain for all is greatest. Another example is preference utilitarianism which holds that the morality of a choice is to be assessed in terms of the desire satisfaction or preference fulfillment it achieves for the greatest number. As such, both, classic and preference utilitarianism, advocate for a monist conception of the Good (i.e., there is only one intrinsic value), which can be contrasted with pluralist accounts and their position that intrinsic value may not be easily reduced into a single value. For instance, ideal utilitarianism considers the values of beauty and truth as irreducible components of a theory of value in addition to pleasure (Sinnott-Armstrong, 2019). Needless to say, many more consequentialist moral theories exist—in fact, it has been suggested that any plausible moral theory can be translated into a consequentialist theory (Sinnott-Armstrong, 2019). A common critique of consequentialist moral theories is that they tend to be very demanding. For instance, a literal (or extremist) implementation of classic utilitarianism would require a moral actor to calculate all impacts of an action so as to maximize the expected hedonic value of actions until the end of time. This task seems insurmountable for any human being given our general cluelessness about many of the long-term consequences of our actions (Greaves, 2016). Two options for dealing with this recognition are common for consequentialist thinkers. On the one hand, demanding consequentialist moral theories like classic utilitarianism are sometimes treated as an idealization of what moral actors should aspire to with the full recognition that real world decision making is likely to only ever approximate this ideal. On the other hand, less demanding consequentialist moral theories are being developed in an attempt to align more closely with existing “common sense” intuitions about morality. 2.2.2 Deontology Deontology (from Greek: duty ”deon” and study “logos”) denotes a family of normative moral theories which hold that the morality of choices should be judged by appealing to moral rules rather than their consequences. For example, if there is a moral rule against torture, it is always wrong to torture, even if this could help save the lives of millions as a consequence. To distinguish between universal and culture- bound rules, the term hypernorm has been introduced to denote rules, norms or principles that are common to different legal, religious, economic and philosophical cultures (Donaldson & Dunfee, 1994). Altogether, deontology stands in contrast to consequentialist moral theories. Consider the following. In consequentialism, “the Good” has priority over “the Right”, whereas deontology suggests the opposite, “the Right” has priority over “the Good”. This starting point makes deontology generally less demanding than consequentialism as choices must not always be subservient to the Good to count as morally right, rather what counts is to “simply” not break the rules (Alexander & Moore, 2021). According to Alexander & Moore (2021), two major classes of deontological theories can be distinguished: agent-centered and patient-centered theories. Agent-centered theories take the perspective of moral agents and suggest agent-relative obligations or permissions as reasons for action. For example, parents are commonly argued to have special obligations to their own children that are not shared by other people but also the permission to save their own child even at the cost of not saving one or even more other children to whom they do not have any relation. Core to agent-centered theories is the understanding that agency in the form of intention (or other mental states) and/or actions is morally relevant and, thus, morality is a deeply personal matter. People’s efforts should be directed at “keeping their own moral house in order” (Alexander & Moore, 2021) rather than focusing on the overall good produced. Patient- centered theories are rights-based rather than duty-based and hold, for instance, that humans have the right to not be used only as a means without consent even if this would produce good consequences overall. Thus, any choice or action that violates this right would be seen as morally wrong. Patient- centered theories often justify rights in agent-neutral terms to make them plausible and gain support. A common critique of deontology is the so-called paradox of deontology: if violating rules is bad, is it not better to have fewer violations? If so, would it not be right to break one rule if this would avert a sufficiently large number of other rule breakings? How to satisfactorily resolve this question remains open to debate (Alexander & Moore, 2021). Suggested answers include the adoption of consequentialism or the speculative development of a novel deontological rationality that explains how to account for the significance of numbers without deference to consequentialist reasoning. 595 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 2.2.3 Virtue Ethics Virtue ethics denotes a third broad perspective on normative ethics that can be distinguished from consequentialism and deontology. Instead of emphasizing the moral imperative of the consequences or duty-bound nature of choices, virtue ethics holds that virtue and vice are central and fundamental concepts at the heart of morality (Hursthouse & Pettigrove, 2018). In particular, virtues and vices cannot be reduced simply to traits that produce good consequences (as in consequentialism) or as traits being possessed by those who fulfil their duties (as in deontology). Moreover, other normative concepts such as “the Good” or “the Bad” must be explained in terms of virtues or vices. Virtue ethics has a long tradition dating back to Plato and Aristotle in the West and Mencius and Confucius in the East. Today, four distinct forms of virtue ethics are distinguished: a) eudaimonist virtue ethics, b) agent-based and exemplarist virtue ethics, c) target-centered virtue ethics, and d) Platonistic virtue ethics. While it is beyond the scope of this paper to detail the nuances of these different approaches, we can highlight some of the commonalities that characterize virtue ethics as a distinct school of thought in normative ethics. In particular, almost all approaches to virtue ethics recognize arête (i.e., virtue), phronesis (i.e., practical wisdom) and eudaimonia (i.e., happiness or flourishing) as important concepts (Hursthouse & Pettigrove, 2018). According to Hursthouse & Pettigrove (2018), virtue is a trait of character that is arête or excellent. Unlike a mere habit (e.g., being an early riser), virtue recognizes a well-entrenched disposition of a person. Possessing a virtue means being a certain type of person and embodying a certain complex mindset. Thus, being virtuous is always a matter of degree. For instance, virtue ethicists often distinguish between full virtue and continence (in this context to be understood as “strength of will”). Being fully virtuous would entail acting without a struggle whereas a continent person still needs to exert effort to overcome temptations and unvirtuous desires. Phronesis or practical wisdom is the capability to make wise choices. It is an important component for the development of virtue as virtues may be actualized in a variety of more or less excellent ways. It is sometimes characterized as that which enables a person to do the right thing in any situation and understand what is truly worthwhile, truly important, and thereby truly advantageous in life. Eudaimonia, often translated as happiness or flourishing, refers to a state of “good spirit” and is often argued to be the highest good that humans can achieve. It is associated with states of happiness, wellbeing and human flourishing. Eudaimonia is understood to be the product or even the goal of living a virtuous life. A common critique of virtue ethics is that it does not provide actionable guidance as it does not propose an account of “right action” grounded in clear moral principles. A virtue ethicist might respond to such a critique by emphasizing that consideration of virtues and vices and axiological notions of good and bad already provide ample guidance for how to live and what kind of person one should strive to become, and because of this, an account in deontic terms such as right and wrong or duty and obligation may not be necessary at all (Hursthouse & Pettigrove, 2018). 2.3 Applied Ethics Applied ethics is concerned with the practical application of moral considerations to real world situations because general moral theories and methods are often not specific enough to be applied directly to concrete moral problems in a particular domain (Singer, 2019). Application of ethics may therefore lead to new insights which might in turn contribute back to the discourse on ethics in general. Several fields of applied ethics can be distinguished today, for instance, bioethics is concerned with ethics in relation to the life sciences, environmental ethics is concerned with the ethical dimension of ecological issues, business ethics is concerned with practical ethical questions in the organizational and business realm. Also, with the rise of research on advanced machine learning algorithms in recent years, the topic of artificial intelligence (AI) ethics has seen a dramatic growth of interest (Kazim & Koshiyama, 2021; Müller, 2021). One challenge that all fields of applied ethics have to deal with is the variety of competing ethical theories and viewpoints which characterize contemporary ethics. It can hardly be denied that all major ethical theories may provide useful insights that can inform the application of moral considerations. Taking the domain of IS research as an example, Berente et al. (2011) outline how the rigor vs. relevance debate in IS research (e.g., Agarwal & Lucas Jr, 2005) can be understood as an attempt to reconcile deontological considerations about researcher duties (i.e., requirement for rigor) with consequentialist considerations about the outcomes and impact of work (i.e., requirement for relevance). Both perspectives foreground different aspects that may plausibly be taken to be important for evaluating behavior and are, thus, informative. However, this recognition puts applied ethicists in the bind of having to adjudicate between Communications of the Association for Information Systems 596 Volume 50 10.17705/1CAIS.05028 Paper 28 competing ethical theories which all seem to offer some valuable insights. Moral uncertainty (MacAskill et al., 2020) is a term that has recently emerged to describe this situation as a decision problem. Explicitly recognizing the uncertainty of beliefs about moral theories may allow for the integration of arbitrary moral theories into a framework of consequentialist decision making under moral uncertainty (MacAskill et al., 2020). Although certainly not a silver bullet, the concept of moral uncertainty opens up new vistas for how disputes in applied ethics may be approached in a practical and pragmatic manner. For instance, Newberry and Ord (2021) outline how the analogy of a moral parliament may be used as a novel framing for decision making under moral uncertainty.1 Another challenge in applied ethics concerns the question of who or what is worthy of moral consideration and, thus, belongs in our moral circle (e.g., only humans, all intelligent animals, all animals, ecosystems, etc.; see Singer, 2011). Although most relevant to a consequentialist understanding of ethics, far reaching shifts in our cultural attitude towards slavery, the role of women in society, or the moral status of animals demonstrate that all plausible moral theories must provide answers to this question in practice. 3 Ethics in Design The explicit consideration of ethics in technology design is a relatively recent phenomenon which started to gain more prominence with the advent of increasingly pervasive digital technologies toward the end of the twentieth century (Franssen et al., 2018). A major question in this realm is whether technology can embody values or, put differently, is value-laden. On the one hand, there is the neutrality thesis which holds that technology itself is simply a label for neutral artifacts that may be used for good or bad by its users (e.g., Pitt, 2000). On the other hand, there is the increasingly prominent position that technology design is a purposeful process which constructs technological artifacts to fulfill certain functions that, in turn, make it more or less easy to achieve certain goals over others. Thus, design establishes a propensity in technological artifacts to guide and steer behavior, which seems to make it hard to maintain that technology artifacts remain value-neutral (Van de Poel & Kroes, 2014). Given this recognition, there has been a trend to view technologies not as a deterministic and self-contained phenomenon but as path- dependent and emergent from a process of choices during design and use (Franssen et al., 2018). This has led to an increase in attention on ethical questions in the design of technical artifacts such as “how to design artifacts in an ethics-conscious manner?”, “how to deal with risks and potential unintended consequences of technologies?”, or “how to approach the topic of responsibility in technology design?”. We briefly discuss each in turn. 3.1 Ethics-Conscious Design Approaches A range of ethics-conscious design approaches has been developed in an effort to help designers and engineers integrate ethical considerations into artifact design. One of the most prominent approaches stems from the field of computer ethics and is called Value Sensitive Design (VSD). VSD is positioned as “a theoretically grounded approach to the design of technology that accounts for human values in a principled and comprehensive manner throughout the design process“ (Friedman et al., 2008, p. 70). As Friedman et al. (2008) explain, VSD advocates interlinking conceptual, empirical, and technical investigations in an iterative manner. Conceptual investigations concern fundamental questions about the values and stakeholders implicated in a design project. Empirical investigations of the design context with specific consideration for stakeholder perspectives complement and inform conceptual investigations. Technological investigations concern the properties of the employed technologies and either aims to a) elucidate how they may affect values of concern or b) design value-sensitive solutions. Other approaches for ethics-conscious design include Enid Mumford’s ETHICS approach (Mumford, 1995), value-conscious design (Manders-Huits, 2011), values-inspired design (Purao & Wu, 2013), ethics by design (Brey et al., 2019), participatory design (Bjerknes & Bratteteig, 1995), the use of focus groups for emancipatory purposes (Stahl et al., 2011), or “Design for X” approaches from engineering (Holt & Barnes, 2010). Although none of these approaches should be seen as a panacea for addressing ethical considerations in design, they provide informative starting points and perspectives from which to assess as well as guide specific design projects. For instance, participatory design may be especially applicable 1 The moral parliament analogy assumes that decisions are made based on the outcomes of the negotiations and votes of parliament members, each of which advocating for and representing a certain moral theory. Moral uncertainty is represented by assigning parliament members to moral theories proportional to a person’s credence in those theories. 597 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 in situations when there is already an agreement between involved stakeholders that democratic values are important and less applicable if some stakeholders have a substantially different perspective on the topic (Friedman & Kahn Jr, 2007). Nevertheless, any design project may learn from considering the assumptions that participatory design makes as well as insights that it affords. Thus, becoming familiar with the available ethics-conscious methods and techniques (see e.g., Friedman et al., 2017; Friedman & Kahn Jr, 2007) and considering their potential benefits and limitations is an important step that any professional interested in good design should consider. 3.2 Technological Risks and Unintended Consequences A general issue with the design of technological artifacts is how to deal with associated risks as well as potential unintended consequences (Franssen et al., 2018). Whereas a risk is generally understood to be the product of the probability of an undesirable event and the effect of that event, an unintended consequence is a potentially large-scale impact that has not been foreseen. Technological risks and unintended consequences are inherent to technology design in a world that may usefully be characterized as a highly complex and rapidly evolving ecosystem of interacting complex adaptive systems (Perrow, 2011). Thus, the history of technological development is ripe with examples of both. For instance, airplanes have risks associated with the long-term stability of their frame and global warming is an unintended consequence of the development and global adoption of fossil fuel powered engines since the industrial revolution. Disconcertingly, recent research has started highlighting that technological risks and unintended consequences might actually pose a serious threat to the future of humanity if human-level AI and machine learning algorithms are developed that do not remain aligned with human values (Christian, 2020; Russell, 2019). Moreover, even without consideration of such forward looking scenarios, the multitude of nuclear weapons on earth (arguably) already pose a significant threat for the future of humanity and illustrate the very real potential moral significance of technological risks and unintended consequences (Ord, 2020). How to approach technological risks and potential unintended consequences is the focus of ongoing research. For instance, Brey’s (2012) anticipatory technology ethics is a framework informed by future studies which aim to provide a flexible approach for the ethical analysis of new and emerging technologies. In a similar spirit, Stahl et al. (2010) present the results of the research project ETICA focused on identifying ethical issues of emerging ICT applications, and Wright (2011) proposes a framework for an ethical impact assessment of information technology. Beyond individual approaches, an interdisciplinary field concerned with responsible research and innovation (RRI) has been emerging, amongst others, to help address the dangers of technological risks and unintended consequences associated with the design of new technology artifacts (e.g., Jirotka et al., 2017; Owen et al., 2013; Stahl, 2012a). A hallmark of RRI is an emphasis on anticipation and foresight as part of design processes. Despite such promising developments, dealing with technological risks and unintended consequences remains a hard problem in practice, especially considering the rapid and, as of yet, mostly unregulated speed at which novel digital technologies are being developed and employed in practice (O’neil, 2016; Zuboff, 2015). Compared to the development of physical technologies, digital technologies are generally quicker and less resource intensive to develop, which makes ethical technology assessments proportionally more costly to developers. Yet, digital technologies can generally scale much more efficiently than physical technologies and impact society to an unprecedented degree. In response, many argue for new approaches to socio-technical research focused on artifact assessment (Rahwan et al., 2019) as well as new forms of digital technology governance (Dafoe, 2018; Gasser & Almeida, 2017). For instance, van de Poel (2016) suggests that the introduction of emerging technologies could be treated as social experiments that are carefully monitored for unintended consequences and, thus, limit risk exposure through gradual and incremental rollouts. Other researchers highlight the importance of creating incentive structures that are conducive to cooperative behavior between societies and technology designers (Askell et al., 2019). More work along these lines would help to limit our exposure to technological risks and the unintended consequences of emerging technologies (Bostrom, 2013). 3.3 Responsibility in Technology Design As already alluded to in the preceding section, the question of responsibility has become an increasingly important topic in technology design. This includes the elaboration of responsibility on multiple levels: responsibility on the individual level, responsibility on the organizational level, responsibility on the policy Communications of the Association for Information Systems 598 Volume 50 10.17705/1CAIS.05028 Paper 28 level, and responsibility on the cultural level—with the acknowledgement that these levels interact and influence one another. Responsibility on the individual level is mainly concerned with the personal responsibility of designers, engineers, and other professionals in the context of the development of technological artifacts. Here, codes of ethics or codes of conduct are generally used to articulate and establish widely shared and agreed upon responsibilities that professionals in a specific field hold. For instance, the recently updated Association of Computing Machinery (ACM) Code of Ethics and Professional Conduct (ACM Code 2018 Task Force, 2018) is an attempt to establish such a code for the computing profession. It articulates general ethical principles, professional responsibilities, professional leadership principles, and code compliance principles aimed at all computing professionals including “practitioners, instructors, students, influencers, and anyone who uses computing technology in an impactful way” (p. 1). In addition to the code itself additional resources such as case studies and procedural guidelines are provided to demonstrate and help with the application of the code (ACM’s Committee on Professional Ethics, 2016, 2021). Although codes of ethics seem to be a necessary step for clarifying and communicating the responsibilities individuals have, empirical research has suggested that taken by themselves they may not be effective in terms of changing behaviors (McNamara et al., 2018). Thus, further work aimed at promoting responsible and professional behavior seems desirable. For instance, interdisciplinary work involving ethicists, educational researchers, psychologists and behavior change experts focused on developing effective and scalable interventions to improve personal capabilities for enacting responsible and professional behavior seems like a promising avenue for future research. Responsibility on the organizational level is tightly intertwined with responsibility on the personal level and is often associated with the Problem of the Many Hands (PMH) which refers to the problems associated with individual accountability and the ascription of responsibility in collective settings (Franssen et al., 2018). Here, the question becomes how can organizations be designed and managed in a way that responsibility is taken up as a priority and not avoided or unintentionally diffused and lost between the cracks? Whole research streams such as corporate social responsibility have been devoted to this question in general (e.g., Lindgreen & Swaen, 2010) but more recent developments include a strong focus on articulating specific guidelines for responsible technology development in the context of emerging AI ventures—so called AI Ethics (Hagendorff, 2020; Kazim & Koshiyama, 2021). However, researchers have highlighted the challenge associated with ensuring responsible behavior in the business sector and emphasized the need for more comprehensive solutions such as thoughtful and informed regulation (e.g., Askell et al., 2019; Mittelstadt, 2019). Responsibility on the policy level is concerned with the question of how laws and regulations can be used to help foster responsible behavior across scales. Currently, all major governments of the world are deeply considering how to regulate emerging technologies and in particular novel AI ventures (e.g., European Commission, 2020, 2021; The National Artificial Intelligence Initiative, 2021) and academia is increasingly aiming to inform these efforts through emerging research fields such as AI Governance (e.g., Dafoe, 2018) and RRI (e.g., Stahl, 2011; Stilgoe et al., 2013). Given the unprecedented challenges associated with emerging technologies (Bostrom, 2013), going forward it should be expected that an increasing amount of resources and attention will be directed to policy relevant efforts. Finally, responsibility on the cultural level is concerned with the narratives, paradigms and logics which encompass and frame all preceding levels. Here, an increasingly prominent view is that individual and societal development can be effectively framed in terms of an ongoing cultural evolution of which technology is an important part (Richerson & Christiansen, 2013). Intriguingly, cultural evolution scholars have recently started to consider cultural evolution itself in terms of an applied and interventionist field aimed at the conscious design of sustainable and prosocial cultural systems (Wilson et al., 2014). Building on such developments, future research may look to cultural evolution as a unifying framework for responsible technology development across levels (e.g., Rahwan et al., 2019; Ronfeldt & Arquilla, 2020; Wilson et al., 2014; Wilson & Gowdy, 2013). 4 Ethics in Science In science, ethics is a topic that has garnered significant attention after large-scale scandals of unethical behavior by scientists became known during the twentieth century (Fisher & Anushko, 2008). In particular, prisoner experiments by the Nazi scientists and the now infamous Tuskegee Syphilis study by American scientists made it clear that scientists could not always be trusted to behave in ways that the general 599 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 public would deem ethical. In response, national and international guidelines for biomedical research were established around three general ethical principles (Fisher & Anushko, 2008, p. 96):  Beneficence: the obligation to maximize research benefits and minimize research harms;  Respect: the responsibility to ensure that research participation is informed, rationale, and voluntary;  Justice: the obligation to ensure the fair distribution of research benefits and burdens across populations. Over time, similar guidelines and principles have been established for the social sciences. Today, most developed and increasingly also developing nations have established mechanisms such as Institutional Review Boards (IRB’s) at universities to oversee and ensure adherence to these guidelines and principles. However, as already alluded to in the section on ethics in design, recent developments toward more powerful emerging technologies are starting to stretch the limits of guidance and expertise that IRB’s can reasonably provide. More flexible approaches such as discourse ethics (Mingers & Walsham, 2010) with a focus on proactive anticipation and discussion of ethical issues have been suggested as a possible way forward (Stahl et al., 2019). Another contentious question in science is the inherently ethical concern about the role and responsibilities of scientific fields in relation to societies. The value-free ideal of science holds that the sciences have the right and, for some, even the duty to engage in creative inquiry without being overly considerate of the ethical consequences of such work. Given this perspective, science is best left free of value considerations so as to remain a bastion of objectivity and authority on truth about the universe (e.g., Hudson, 2016). In contrast, opponents of this view have forcefully argued that science such as any other human activity is saturated with values (e.g., any acceptance or rejection of a hypothesis requires value judgments about the available evidence) and, ultimately, always a reflection of the values of the involved actors (e.g., Churchman, 1995; Douglas, 2009; Ulrich & Reynolds, 2010). To some degree the disagreement between these two camps may be traced back to differences in metaphysical and epistemological assumptions about the universe but are also at heart, maybe ironically, differences in value judgements about the proper role of the sciences in society. Are science fields best kept solely focused on the reliable production of knowledge concerning the behavior of the universe or are science fields better when explicitly directed to aid in the responsible development of humanity’s future? Different answers in the form of competing scientific paradigms are likely to emerge as the future unfolds. 5 Ethics in IS Practice Given the history and development of the IS field at the intersection of management, organizational and computer science, the consideration of ethics in IS practice falls under the purview of business ethics as well as disciplinary codes of ethics and professional conduct such as the one developed by the ACM (ACM Code 2018 Task Force, 2018), which was already introduced in the section Ethics in Design. Business ethics is generally conceived of as “the study of the ethical dimensions of the exchange of goods and services, and of the entities that offer goods and services for exchange” (Moriarty, 2021). Similar to other applied ethics fields, business ethicists have adapted general moral theories such as consequentialism, deontology, and virtue ethics to the business domain and considered and developed their implications. To elaborate on these challenges, we draw on the substantial expertise and experiences from the authors to flesh out two key challenges for ethics in IS practice: a lack of skills and resources and value conflicts. 5.1 Challenge: Lack of Skills and Resources Considering the speed at which new digital technologies and computing applications are being rolled out, staying up-to-date on the latest developments in the computing field is a common challenge almost any IS practitioner can relate to. To illustrate the dilemma, we refer to the famous quote by Lewis Carroll (1899): “Now, here, you see, it takes all the running you can do, to keep in the same place. If you want to get somewhere else, you must run at least twice as fast as that!” Given such stringent demands for adaptation and lifelong learning, it is not surprising that not all IS professionals are always able to make decisions that are not only ethically directed but also competent, based on the most suitable technologies, and backed by the best available evidence. However, given the technological risks and potential unintended consequences of many IS projects today, this situation is increasingly untenable. Communications of the Association for Information Systems 600 Volume 50 10.17705/1CAIS.05028 Paper 28 As an example, consider the case of the use of IBM’s Watson to improve cancer care (Strickland, 2019). The aim here was to do something good, that is, improve health care and benefit patients. The system, however, despite having been deployed worldwide, has been criticized for relatively poor performance (Ross & Swetlitz, 2017). One criticism is that the data set used to train the system was biased to the specific conditions that were present at the hospital where the system was initially developed. Thus, without implying any kind of malicious intent, it appears that the developers of the system either lacked the skills or resources to avoid rolling out and selling a potentially dangerous solution. This is despite a clear warning in the ACM Code of Ethics and Professional Conduct that “Extraordinary care should be taken to identify and mitigate potential risks in machine learning systems. A system for which future risks cannot be reliably predicted requires frequent reassessment of risk as the system evolves in use, or it should not be deployed” (ACM Code 2018 Task Force, 2018, p. 6). Building on the preceding example, we must also recognize that businesses and other organizations are often not designed to enable practitioners to make right or good but profitable decisions. Genuine and deep concern for corporate social responsibility, that actually empowers employees to build up the skills and resources necessary to make difficult ethical decisions, is (despite increasing attention and efforts, at least from an anecdotal perspective) still very hard to come by. Similar to the predicament of the IS professional, organizations are often pressured by relentlessly ongoing change and economic narratives focused on competition and growth as maxims for business. Against this backdrop, a lack of skills and resources for ethical concerns is likely to be a formidable challenge for ethics in IS practice at least in the near future. It seems fruitful and important to investigate ways in which ethical and competent behavior can be supported by identifying and developing effective tools, teaching formats, work paradigms, and other supporting infrastructure, always informed by already existing mechanisms and interventions such as codes of conduct, ethics courses at universities, or professional training. 5.2 Challenge: Value Conflicts Another important challenge for ethics in IS practice is tied to the general observation that in modern societies a broad diversity of value systems exist (e.g., Awad et al., 2018). A logical consequence of this observation is that the presence of multiple value systems can precipitate potential tensions around conflicting values and how to deal with them. For instance, the moral machine experiment by Awad et al. (2018) highlights that people with different cultural backgrounds have different moral intuitions about who to save or not to save in a thought experiment about an unavoidable accident involving an autonomous car. Thus, major ethical questions regarding the development of algorithms for autonomous cars arise. Should moral intuitions be taken as authoritative and algorithms be tailored to the cultural norms of a country? Is an autonomous car manufacturer allowed to simply choose what kind of algorithm it wants to implement? Or is there one true and right way to design the algorithm that all autonomous car manufacturers ought to converge on? And how many resources do we need to invest to test and ensure that developed algorithms actually align with the goals that the developers intended? Finding practical ways of dealing with such ethically charged questions around value conflicts is likely to be a major concern for many IS practitioners going forward. The more we digitalize the world and try to manage it with algorithms, the more we need to become explicit about our own value systems and how these relate to others. Extant research on ethics can inform such efforts but ultimately the IS professionals must find a way to consider these lessons to make informed and responsible decisions before designing and implementing solutions. For example, in the section Applied Ethics we have already presented some recent ideas around the notion of moral uncertainty, which could provide a useful reference point for any work that is faced with value conflicts and wants to approach them with explicit consideration of different moral theories. Furthermore, the methods and techniques mentioned in the section Ethics-Conscious Design Approaches provide a more design-oriented perspective on how to engage with values in design. In addition, Habermas’s discourse ethics (Mingers & Walsham, 2010) should be seen as another informative reference point, as it provides a set of procedural guidelines for dealing with value conflicts through open discourse and argumentation. In a similar vein, Ulrich’s (2006) critical pragmatism informed by his work on critical systems heuristics (e.g., Ulrich & Reynolds, 2010) offers the dialectic application of boundary critique as a means for surfacing and engaging with conflicting viewpoints and value systems. In sum, all of these concepts and approaches may offer useful insights when dealing with value conflicts in IS practice but should not be seen as a panacea. Dealing with value conflicts can become a formidable challenge and may require deep engagement, expertise, and many iterations to get “right”. 601 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 6 Panelists' Perspectives on Ethics in Design Science Research Integrating the preceding discussions, what can now be said about the specifics of ethics in DSR? In the following, we will first introduce and then present individual viewpoint statements by four distinguished DSR scholars, namely, Matti Rossi, Monica Chiarini Tremblay, Sandeep Purao, and Shirley Gregor, who participated in a panel to discuss the role of ethics in DSR at DESRIST 2020. The panel was organized and coordinated by Alexander Herwix and Amir Haj-Bolouri who join the panelists in offering an individual viewpoint. Together, the set of viewpoints offers a broad and diverse set of perspectives to illuminate how different scholars have experienced the challenges related to ethics in their scholarly journey so far. 6.1 Matti Rossi Matti Rossi is a professor of IS at Aalto University School of Business. He is a past president of the Association for Information Systems. He was the winner of the 2013 Millennium Distinction Award of Technology Academy of Finland for open source and data research. He is one of the co-authors of the seminal MIS Quarterly paper on Action Design Research (ADR) (Sein et al., 2011). 6.1.1 Personal Viewpoint Matti Rossi emphasizes the importance of ethics for any kind of design work as well as the study of designed artifacts. This stance is reflected in his affiliation with the Scandinavian Tradition in IS development, which advocates for a democratic and stakeholder value-oriented perspective on IS and organization design. The Scandinavian Tradition is one of the precursors of the participatory design approaches mentioned earlier. The key insight from the Scandinavian Tradition is that ‘what makes the systems work’ is a good understanding of the actual work processes, which allows to fit the data processing needs of the managers with the information needs of the workers (Bjerknes & Bratteteig, 1995; Ehn & Kyng, 1987). From the design perspective this means that the users should have power to influence the decisions about system functionality (Bjerknes & Bratteteig, 1995) and that there should be explicit design goals for improving the work situation. From an ethics perspective this is clearly a form of value-oriented design, but it is important to note that there is no need for perfect stakeholder agreement on issues, rather the conflicts between stakeholders should be seen as a necessary means to uncover all of the involved values and goals. He stresses the underlying philosophy of trying to ensure that DSR is performed in a way that is ethically sound and benefits all the parties involved, not just the researchers or managers. He believes that if researchers take such recommendations and principles seriously, it can help to gain the trust of the practitioners, design more ethically sound systems, and generate more appropriate design principles. In his work, he has been faced with choices that he perceived to have deeply ethical components. For instance, he and his colleagues were approached by an arms development company that wanted to collaborate on a DSR project. Ultimately, they decided against this cooperation pointing to ethical concerns about the potential consequences of the project. So, even before the DSR project was initiated, ethics was perceived to be a relevant factor. In terms of recommendations for research practice, he advocates a democratic and stakeholder-oriented approach to DSR. Looking forward, he urges the IS community to take the increasingly pervasive role of IS in society more seriously and investigate it from ethically informed viewpoints that help us navigate towards positive futures and identify the negative futures to be avoided. 6.2 Monica Chiarini Tremblay Monica Chiarini Tremblay is a Professor of Business Analytics at William & Mary's Raymond A. Mason School of Business. She is an active DSR scholar with much of her research focused on data analytics and technology adoption and sustainability in the healthcare context. Her work has touched on topics that impact vulnerable communities such as foster children, cancer patients, and veterans. Thus, she has to consider the three general ethical principles of beneficence, respect, and justice (Fisher & Anushko, 2008, p. 96) concerning the vulnerable populations that provide the context for her research. 6.2.1 Personal Viewpoint Monica Chiarini Tremblay emphasizes that ethical concerns occur throughout the DSR process. Many choices can have severe consequences and not all of them are naturally good. For instance, as social Communications of the Association for Information Systems 602 Volume 50 10.17705/1CAIS.05028 Paper 28 media demonstrates, even good design can have adverse effects. Thus, she suggests that as DSR scholars we have the responsibility to consider the ethical consequences of our actions at every step of the DSR lifecycle. She illustrates this point with an anecdote where she (as a reviewer) felt compelled to reject a paper based on its perceived ethical implications, specifically beneficence. The proposed artifact, which predicted microloan default risk based on social media behavior, would negatively impact precisely those who most need microloans. In terms of recommendations for research practice, she highlights several examples in her own work. First, early in her career, she collaborated with a critical theorist to study the emancipatory ways IS researchers can use focus groups to collect data (Stahl et al., 2011). This work has guided much of her design science work—directing her to consider whether all relevant and identifiable stakeholders are represented and identify opportunities to emancipate both the researcher and the participants. A second example is a recent study where she and her colleagues were using data from a foster care agency to illustrate the efficacy of a method that organizes data to improve the transparency and performance of machine learning models. One particular piece of data was a perfect example of the effectiveness of their artifact but also highlighted a problematic inefficiency of that foster care agency. The team decided to use a less compelling illustration of the method. Foster care agencies are notoriously under-funded and over-burdened by federal and state regulations. Often data can be weaponized to support competing political views, thus, care should be taken when communicating research results. Though it was unlikely that stakeholders in foster care would read an article in an academic IS journal, it was still important to communicate carefully to reduce the chance of unintended consequences for a cooperating research subject (in this case the agency). Altogether, she highlights how one must take ethical considerations seriously at every step of the design science cycle. For example, her colleagues used action design science research to design a mHealth application for lung cancer care (Tremblay et al., 2020). The mHealth application utilized service-dominant logic to guide the design of a mHealth app that creates value for clinicians, patients, and caregivers. Stakeholder involvement is paramount in the design phase, but the author team debated the beneficence of involving lung cancer patients in the early stages. Lung cancer patients are often very ill. They are not in a mental state conducive to novel conceptualizations, such as imagining the requirements for the design and development of an application. The medical literature advocates taking exceptional care when incorporating patients at a vulnerable time in their lives (i.e., terminally ill patients); it is often preferable to refer to proxies instead (Reid, 2009). The research team worked with clinicians, clinician associations, and patient advocacy groups to collect the requirements and then create the beta version of the application. The team then consulted with healthcare policy and cancer research colleagues to determine if it was appropriate to conduct focus groups with patients to evaluate the beta version of the mHealth app. With the guidance of these experts, the team designed the focus groups that treated patients with respect by 1) articulating their situation in an objective and non-judgmental climate, 2) motivating them to consider how being involved in the focus group with other cancer patients could be an interesting escape from normality, and 3) making them aware that the information they provide might help in future planning and delivery of care to others (Reid, 2009). This thoughtful research design paid off and contributed significantly to a successful research project. 6.3 Sandeep Purao Sandeep Purao is Trustee Professor at the Information and Process Management Group at Bentley University, and Visiting Professor at Agder University, Norway. His current research focuses on the design of technology for the social good, and the sciences of design with research projects that deal with the homeless, the elderly, and domains such as fake news. He is also one of the co-authors of the seminal MIS Quarterly paper on ADR (Sein et al., 2011). He is the recipient of the DESRIST Lifetime Achievement Award in 2014. 6.3.1 Personal Viewpoint Sandeep Purao argues that ethics and responsible behavior are an integral part of DSR and a prerequisite for effective outcomes. He views ethical behavior through two perspectives, one focused on the actions themselves (i.e., a deontological approach to ethics), the other focused on the consequences of the actions (i.e., a consequentialist approach to ethics). His approach to reconciling the two perspectives involves evaluating the actions and behaviors of human actors by examining the personal circumstances and context of the actor. Such a perspective can provide a basis to understand visible 603 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 conflicts between the actors, and trace these, not only to the potential value conflicts but also how these values are formed by the actors. For him, this contextual perspective of ethics requires a self-reflective mindset that is open to criticism and feedback. For instance, he proposes that IS scholars should be more reflective about the research problems they choose, and become more aware of possible criticism of outcomes they report. He further suggests that DSR scholars should become more concerned about the distal and unintended consequences of their work that remain difficult to appreciate because of the limits on the duration of research projects. In an exposition of some of his own research (Purao & Wu, 2013), he highlights the inherently ethical nature of DSR by emphasizing that the novel IT artifacts that DSR scholars generate can enhance or reduce the potential for action (echoing the quote from van den Hoven in the opening passage of this paper: “[designs and artifacts] are all formidable shapers of the world we inhabit and in which we acquire our beliefs, decide and act, expect, feel, and hope” (Maedche, 2017)). Accordingly, his perspective about the consideration of values and ethics in the pursuit of DSR is inspired by, and most closely aligns with ideas related to value-sensitive design (Friedman et al., 2008) that is part of the stream of work related to ethics-conscious design (see Section 3.1 earlier). This perspective encourages the DSR scholars to “frontload” considerations of ethics in their research efforts, instead of relegating these to later generations of scholars who would need to sift through the impacts of their work with the lens of unintended consequences (see Section 3.2 earlier). He acknowledges that such a stance can be particularly difficult for DSR scholars who must assume an anticipatory stance (see the ideas from Brey (2012), explored in Section 3.2 earlier). He, therefore, formulates his recommendations for research practice for DSR scholars by urging them to consider work on ethics in design and engineering to become more conscious about how to integrate “values we value” (ethics) into design efforts (Purao & Wu, 2013). In addition to considering the impact of their research efforts on potential users, he suggests that the best reason for DSR scholars to care more about ethics should be self-interest. As one example, he points to work in the direction of mitigating the spread of fake news by developing a more nuanced understanding of how it can spread (Purao et al., 2021). He argues that without adequate consideration of ethics in their pursuit of research, DSR scholars run the risk of creating futures in which they themselves may not want to live. 6.4 Shirley Gregor Shirley Gregor is a Professor Emerita at the Australian National University. Her research interests include artificial intelligence, human-computer interaction and the philosophy of science and technology. She is the co-author of numerous seminal papers on the nature of design theory and how to publish DSR for maximum impact (Gregor et al., 2020; Gregor & Hevner, 2013; Gregor & Jones, 2007). In 2017 she was awarded a DESRIST Lifetime Achievement Award. Of particular relevance to the panel is her service 2007-2008 as the Director of the Professional Standards Board of the Australian Computer Society. 6.4.1 Personal Viewpoint Very broadly speaking, Shirley’s personal views on ethics follow the idea that an individual should avoid doing harm to others and with Kant’s categorical imperative that one should act in accordance with rules that one is willing to recognize as holding universally for everyone: for example, do not be untruthful. Kant’s view is a deontological normative theory as described earlier. However, Shirley’s experiences as a software engineer in the early stages of her career, her time as Director of the Professional Standards Board of the Australian Computer Society and her work on DSR projects have all pointed her to the importance of also considering applied ethics. She recognizes principles such as Kant’s categorical imperative are very general and likely not able to give specific guidance in some of the very complex situations of information systems development, where outcomes are uncertain and different stakeholders have very different interpretations of what is right and wrong. Approaches that Shirley has observed as valuable in practice for providing more specific guidance have commonalities with Habermas’s discourse ethics (e.g., Habermas, 1996), particularly, in cases where so- called substantive hypernorms cannot be identified and sufficiently justified for actual decision-making in organizations. Habermas’s discourse ethics introduces procedural hypernorms that can be used as a starting point for justifying substantive hypernorms, through moral reasoning processes. The basic idea is that the validity of a moral hypernorm cannot be justified by one individual alone, but should be established in a process of argumentation amongst involved individuals. This approach appears to be of Communications of the Association for Information Systems 604 Volume 50 10.17705/1CAIS.05028 Paper 28 practical value and gives backing for some of the procedures that are observed in IS development, human-centered design and in codes of good conduct for computer professionals. Considering applied ethics further, Shirley Gregor emphasizes the importance of ethical behavior through the lens of professional behavior and associated codes of ethics. Professional behavior is deemed particularly important for DSR scholars who often work at the frontier of technology where potential negative outcomes and externalities are always in the cards. She suggests that in such situations “doing things right” (e.g. meaningful involvement of stakeholders, testing software adequately) is as important as “doing the right thing” (i.e. aiming at goals that benefit society). Shirley has seen cases on DSR projects where researchers did not act professionally and where this behavior could be seen as unethical. In one case a project leader undertook a workshop to design the interface for a new system, although his experience in human-computer interaction was negligible. Experts in the field outside the project could see that the resultant design was unsatisfactory, but the industry partners could not. Other project team members were put in the very difficult position of deciding whether to speak up about the problem or not. The case was particularly difficult because of power imbalances amongst the researchers. Sadly this case is not unusual and IS researchers, along with professionals in many fields, may find themselves having to choose between doing things right and suffering repercussions in their employment. 6.5 Alexander Herwix and Amir Haj-Bolouri Alexander Herwix is a doctoral candidate at the University of Cologne in Germany and currently mainly concerned with the theoretical and practical advancement of DSR. Amir Haj-Bolouri is an Associate Professor at University West in Sweden and focuses on questions and phenomena concerning design, immersive technologies (e.g., Virtual Reality, Augmented Reality), philosophy, and learning. 6.5.1 Personal Viewpoint Alexander Herwix and Amir Haj-Bolouri strongly advocate for the centrality of ethical considerations for any type of research (Herwix & Haj-Bolouri, 2021) and DSR in particular (Herwix & Haj-Bolouri, 2020). At heart, all decisions that we are making are either implicitly or explicitly a reflection of our values (Ulrich, 2006). As such, an understanding of ethics is paramount for the assessment of IS research and can help to improve its relevance and impact (Herwix & Haj-Bolouri, 2021, 2020). In particular, they argue that we need to be explicit about the values we consider to be the motivation of our work. But we also need to follow through in terms of measuring our progress towards achieving them when assessing our work. For instance, if we are seriously interested in contributing to sustainability, we need to make explicit what exactly we mean by that and how much sustainability our work helps to create for each dollar that is spent on it. The same goes for more traditional values like organizational value realization or academic knowledge. Making progress on this front seems especially important to them given that recent reviews have suggested that most papers in IS journals right now only make shallow arguments (e.g., focused only on direct and easily measurable effects or no empirical support at all) for the practical import of their work (Moeini et al., 2019; Spindeldreher et al., 2020). As such, they advocate for clearer guidelines around how to report and communicate our work in an ethically conscious manner. Altogether, they view ethics not as a fixed set of beliefs but as a pragmatic and continually evolving process of collective inquiry aimed at identifying and justifying wise behavior (Grossmann et al., 2020; Ulrich, 2006). As Ulrich (2006) outlines, the boundaries we draw to make sense of the world inherently affect the facts and judgements we make and vice versa. Thus, we must become experts at justifying and documenting the boundary judgements we are making, if we are to hope for moral progress. As such, they view ethics as inherently and intimately related to the practice of doing DSR which is itself concerned with the question of how to improve our actions in the world through the design of useful artifacts (Herwix & Zur Heiden, 2022; Hevner et al., 2004). They agree that in a very real sense, “science and ethics ultimately converge” (Ulrich, 2006, p. 67). Their viewpoint emerges from an engagement with several different bodies of knowledge including pragmatism (e.g., Ulrich, 2006), systems thinking (e.g., Churchman, 1995), effective altruism (e.g., MacAskill, 2015), and cognitive science (e.g., Grossmann et al., 2020) as well as wrangling with the practice of doing DSR. 605 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 7 Discussion and Recommendations Evident in the personal viewpoint statements is the agreement among the panelists that ethics remains a critical consideration for IS research in general, and DSR in particular. The very nature of DSR, aimed at designing innovative artifacts and solving real world problems, may, in fact, need to be defined in terms of such value considerations (see also Churchman, 1995; Ulrich, 2006). The panelists further agree, and the preceding review of prior work provides the rationale to point out, that this can be challenging for a number of reasons, including the need to be more reflective (Purao & Wu, 2013), more anticipatory (Brey, 2012), more aware (Herwix & Zur Heiden, 2022), and more informed about the many different perspectives and contemporary debates about the nature of ethics and values (e.g., Singer, 2019). Beyond these larger concerns, there is one immediate issue (also see the preceding discussions on responsibility in design and the challenges for ethics in IS practice) that the panelists acknowledge: the incentive structures within academia that do not acknowledge nor support mechanisms to surface these considerations. For instance, Tremblay et al. (2018) outline how the prevailing quantification of faculty productivity in interplay with entrenched publication norms seems to—at least to some degree— discourage the conduct of DSR. Restructuring such incentive systems to be more conducive to responsible forms of IS research such as ethics-conscious DSR is a difficult challenge. Any transformation in this space is likely to be a very slow and political process that needs to propagate across disconnected universities and journals. As an example, accreditation guidelines are only updated in multi-year intervals and even then, might not be as responsive to change as would be desirable. There are, however, some promising moves in this direction with the recognition of thought leadership and societal impact within the AACSB standards formulated in 2020. Although these do not specifically acknowledge the role of values and ethics, phrases such as societal impact can provide IS scholars new pathways to consider how their work can be guided by concerns of societal value. In spite of these recent moves, work to transform the system remains limited in scope and effect. Real and measurable changes will require hard work and a sustained effort by many scholars in the IS community and beyond. However, given what is at stake, this panel took the position, as outlined in this report, that responsible forms of IS research such as ethics-conscious DSR ought to become the norm in the IS field. In the following, we offer three concrete recommendations that may help us in realizing this effort: encouraging value reporting, engaging in problem prioritization, and improving the research infrastructure. 7.1 Encouraging Value Reporting We suggest that there is an opportunity to improve the ethical awareness in DSR (and IS research in general) by promoting mechanisms such as “value reporting.” By this, we mean the explicit positioning of papers with regard to the underlying value systems that the authors used or considered. One approach to realizing this goal could take the form of a paragraph in the theory development or method section of a paper (or even become a separate section either in the paper or separately as an appendix), where the work is mapped to the main values that the authors want to promote (see Appendix A for two examples). Such value reporting can improve the openness and transparency of research and nudge authors toward explicit reflection about how their work relates to their espoused or professed value system. Such increased transparency about values would help the IS community to become more self-reflective about the values it promotes, more transparent with regards to potential value conflicts, and also more attuned to novel research opportunities. In particular, it would become much more apparent if non- traditional values such as sustainability or justice have been neglected compared to more traditional values such as business success. In this vein, a recent review indicated that the majority of IS research analyzed used predominantly economic market values (e.g., profit, competition, etc.) to justify their work and neglected other potential values such as sustainability (Spindeldreher et al., 2020). Thus, encouraging authors to reflect and report on the values that provide the basis for their work may help to foster novel research perspectives and more ethics-conscious problem framings. Moreover, value reporting could create efficiencies by helping to align author intentions and reviewer expectations. Transparent and explicit value reporting by the authors of a paper may help reviewers appreciate their intent in a way that potential ethical concerns can be addressed outright. For instance, if a paper addresses a controversial or ethically delicate topic, having clarity around the motivations and intents of the authors can help editors and reviewers make better informed decisions about the paper and offer suggestions for improvement. We provide examples of value reporting in Appendix A to this paper: one that uses this paper as an example, and the other based on a recent paper from one of the authors. Communications of the Association for Information Systems 606 Volume 50 10.17705/1CAIS.05028 Paper 28 7.2 Engaging in Problem Prioritization Considering the impact that the choice of research problems has on the potential relevance of the IS field, we join others in advocating for a more systematic and serious engagement with problem choice, framing, and prioritization (e.g., Becker et al., 2015; Chen, 2011; Gable, 2020; Herwix & Haj-Bolouri, 2020, 2021; Mertens & Barbian, 2015; Purao, 2021; Rai, 2017; Winter & Butler, 2011). Put simply, our work can only be as important as the problem which it is addressing. Here, ethics can provide helpful support to more rigorously assess the importance of research problems against various perspectives on what truly matters (see Herwix & Haj-Bolouri, 2021, 2020). Thus, ethics and applied ethics in particular can provide helpful kernel theory which may inform the discourse around research problem priorities in IS research. In essence, this can provide a more rigorous theoretical grounding for how topic selection decisions are made and contribute to the justifiability and expected impact of the IS field. As such our recommendation is strongly congruent with and supportive of recent calls for a more strategic orientation in IS research (e.g., Gable, 2020; Winter & Butler, 2011). Building on the above precursors, we encourage future IS researchers to engage in problem prioritization on two levels. First, we encourage individuals and teams of researchers to systematically engage in ethics-conscious problem prioritization in the context of their own work. Several researchers already provide useful starting points for informing such efforts (e.g., Herwix & Haj-Bolouri, 2021, 2020; Herwix & Zur Heiden, 2022; Purao, 2021; Rai, 2017). Second, we hope that the IS community as a whole will proactively support further development of mechanisms and approaches that can help to establish systematic and ethics-conscious problem prioritization as a self-organizing feature of the IS field. For instance, specific sections in our top journals could be dedicated to systematic and ethics-conscious discourse about problem priorities in our field and regular special issues be used to incentivize work on the most pressing topics. Prior work on grand challenges for IS research may provide a useful starting point to inform such efforts (e.g., Becker et al., 2015; Chen, 2011; Mertens & Barbian, 2015; Winter & Butler, 2011). 7.3 Improving Research Infrastructure Building on and extending the two preceding recommendations, we suggest that there is a general opportunity to systematically work on developing a comprehensive research infrastructure (i.e., the sociotechnical ecosystem supporting our research efforts; e.g., Dutton, 2011; Morana et al., 2018) that supports and encourages ethical behavior and work. As Winter and Butler (2011) highlight, the DSR community (as well as the broader IS community) can leverage its expertise to help design and build the research infrastructure (e.g., with the suggestion of possible solutions, the construction and evaluation of prototypes, or the identification of useful design principles) that is necessary to tackle large scale challenges of societal relevance and ethical import. This type of work seems highly promising from an expected impact perspective as research infrastructure developed for the IS field may be exapted to other fields and, thus, contribute to improving the overall research infrastructure at large. For instance, the IS community could develop new citation measures that would help to redefine a research communities notion of academic success to be more appreciative of ethical concerns and shape its development trajectory significantly in the long run (e.g., Fitzgerald et al., 2019). Moreover, self-reflective work aimed at improving our ability to carry out ethics-conscious and responsible research more effectively and efficiently could create virtuous feedback loops that enhance the quality and legitimacy of our work. For instance, citizen science projects in fields like astronomy demonstrate that large gains in research quality and productivity are possible if sociotechnical research infrastructure is leveraged in the right way (Watson & Floridi, 2018). Beyond such advanced technological solutions there is also room for the development of innovative teaching formats that are aimed at increasing ethical awareness and competence (e.g., Berti et al., 2021; Parks-Leduc et al., 2021). Given such opportunities, we posit that the IS community should use at least some of its resources to self- reflectively look for and develop innovative improvements to the research infrastructure. To support such efforts, assessment criteria and decisions for or against publications could be made more transparent. Today, peer review in IS journals remains an opaque process, where acceptance or rejection decisions and underlying reviews are kept from public scrutiny. To increase the transparency and quality of the peer review process, open peer review practices (Ross-Hellauer, 2017) may help. Further, institutional support for working with preprints can also be considered. For instance, publishing anonymous reviews alongside preprints would improve the communities understanding of current review practices and provide a foundation for systematic attempts to improve review quality and, ultimately, research outcomes. Preprints 607 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 provide a transparent and, in other fields already widely accepted, mechanism for the open-access publication of research designs and outcomes, which improves the visibility of research findings (Fu & Hughey, 2019) and also enable innovations in the research infrastructure (e.g., Sinapayen, 2021). 8 Conclusion In this report, we have discussed ethics in relation to IS research in general and DSR in particular from four intersecting perspectives: philosophy, design, science, and IS practice. As we have outlined, each of these perspectives provides important concepts and considerations that can inform our own work at the intersection of these fields (an integrative, fifth perspective). Our work is informed by discussions and ensuing reflections at a panel of senior DSR scholars at DESRIST 2020 and builds on deep insights into the real-world significance of ethics in the context of IS research and practice that each of the panelists offers. We hope that our integrative work and reflections can provide a fruitful starting point for more systematic and deliberate engagement with ethics in IS research and DSR in particular. As we outline in this paper, our collective experience suggests that our field and all of its stakeholders only stand to benefit from it. Communications of the Association for Information Systems 608 Volume 50 10.17705/1CAIS.05028 Paper 28 References ACM Code 2018 Task Force. (2018). ACM code of ethics and professional conduct. ACM. Retrieved from https://dora.dmu.ac.uk/bitstream/handle/2086/16422/acm-code-of-ethics-and-professional- conduct.pdf?sequence=1&isAllowed=y ACM’s Committee on Professional Ethics. (2016, June 24). Using the code. ACM Ethics. Retrieved from https://ethics.acm.org/code-of-ethics/using-the-code/ ACM’s Committee on Professional Ethics. (2021). Proactive CARE for Computing Professionals. ACM Ethics. Retrieved from https://ethics.acm.org/wp-content/uploads/2021/03/Proactive-CARE-for- Computing-Professionals.pdf Agarwal, R., & Lucas Jr, H. C. (2005). The information systems identity crisis: Focusing on high-visibility and high-impact research. MIS Quarterly, 29(3), 381-398. Alexander, L., & Moore, M. (2021). Deontological ethics. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Summer 2021). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/sum2021/entries/ethics-deontological/ Askell, A., Brundage, M., & Hadfield, G. (2019). The role of cooperation in responsible AI development. ArXiv:1907.04534 [Cs]. Retrieved from http://arxiv.org/abs/1907.04534 Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.-F., & Rahwan, I. (2018). The Moral Machine experiment. Nature, 563(7729), 59-64. Becker, J., vom Brocke, J., Heddier, M., & Seidel, S. (2015). In search of information systems (grand) challenges: A community of inquirers perspective. Business & Information Systems Engineering, 57(6), 377-390. Benke, I., Feine, J., Venable, J., & Maedche, A. (2020). On implementing ethical principles in design science research. AIS Transactions on Human-Computer Interaction, 12(4), 206-227. Berente, N., Gal, U., & Hansen, S. (2011). Ethical implications of social stratification in information sys- tems research. Information Systems Journal, 21(4), 357-382. Berti, M., Jarvis, W., Nikolova, N., & Pitsis, A. (2021). Embodied phronetic pedagogy: Cultivating ethical and moral capabilities in postgraduate business students. Academy of Management Learning & Education, 20(1). Bjerknes, G., & Bratteteig, T. (1995). User participation and democracy: A discussion of Scandinavian research on system development. Scandinavian Journal of Information Systems, 7(1), 73-98. Bostrom, N. (2013). Existential risk prevention as global priority. Global Policy, 4(1), 15-31. Bourget, D., & Chalmers, D. J. (2014). What do philosophers believe? Philosophical Studies, 170(3), 465- 500. Brey, P. (2012). Anticipatory ethics for emerging technologies. NanoEthics, 6(1), 1-13. Brey, P., Lundgren, B., Macnish, K., & Ryan, M. (2019). Guidelines for the ethical development of AI and big data systems: An ethics by design approach. SHERPA. Retrieved from https://www.project- sherpa.eu/wp-content/uploads/2019/12/development-final.pdf Carroll, L. (1899). Through the looking-glass and what alice found there. G.H. McKibbin. Chen, H. (2011). Editorial: Design science, grand challenges, and societal impacts. ACM Transactions on Management Information Systems, 2(1), 1-10. Christian, B. (2020). The alignment problem: Machine learning and human values (1st edition). W. W. Norton & Company. Churchman, C. W. (1995). Ethics and science. Systems Research, 12(4), 267-271. Dafoe, A. (2018). AI governance: A research agenda. Future of Humanity Institute. Retrieved from https://www.fhi.ox.ac.uk/wp-content/uploads/GovAIAgenda.pdf 609 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 Dancy, J. (2017). Moral particularism. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Winter 2017). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/win2017/entries/moral-particularism/ DeLapp, K. (n.d.). Metaethics. Internet Encyclopedia of Philosophy. Retrieved from https://iep.utm.edu/metaethi/ Donaldson, T., & Dunfee, T. W. (1994). Toward a unified conception of business ethics: Integrative social contracts theory. Academy of Management Review, 19(2), 252-284. Douglas, H. E. (2009). Science, policy, and the value-free ideal (1st ed.). University of Pittsburgh Press. Dutton, W. H. (2011). The politics of next generation research: Democratizing research-centred computational networks. Journal of Information Technology, 26(2), 109-119. Ehn, P., & Kyng, M. (1987). The collective resource approach to systems design. Computers and Democracy, 17-57. Ethics. (n.d.). In Cambridge English Dictionary. Retrieved from https://dictionary.cambridge.org/us/dictionary/english/ethics European Commission. (2020). White paper on artificial intelligence - A European approach to excellence and trust. European Commission. Retrieved from https://ec.europa.eu/info/sites/info/files/commission-white-paper-artificial-intelligence- feb2020_en.pdf European Commission. (2021). 2030 digital compass: The European way for the digital decade. European Commission. Retrieved from https://digital-strategy.ec.europa.eu/en/policies/europes-digital-decade European Group on Ethics in Science and New Technologies. (2018). Statement on artificial intelligence, robotics and “autonomous” systems. European Commission. Retrieved from https://op.europa.eu/en/publication-detail/-/publication/dfebe62e-4ce9-11e8-be1d-01aa75ed71a1 Fisher, C. B., & Anushko, A. E. (2008). Research ethics in social science. In D. M. Mertens & P. E. Ginsberg (Eds), The SAGE Handbook of Social Research Methods (pp. 95-109). Sage. Fitzgerald, B., Dennis, A. R., An, J., Tsutsui, S., & Muchala, R. C. (2019). Information systems research: Thinking outside the basket and beyond the journal. Communications of the Association for Information Systems, 45, 110-133. Franssen, M., Lokhorst, G.-J., & van de Poel, I. (2018). Philosophy of technology. In E. N. Zalta (Ed.), The Stanford Encyclopedia of Philosophy (Fall 2018). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/fall2018/entriesechnology/ Friedman, B., Hendry, D. G., & Borning, A. (2017). A survey of value sensitive design methods. Foundations and Trends in Human-Computer Interaction, 11(2), 63-125. Friedman, B., Jr, P. H. K., & Borning, A. (2008). Value sensitive design and information systems. In K. E. Himma & H. T. Tavani (Eds.), The handbook of information and computer ethics (pp. 69-101). Wiley. Friedman, B., & Kahn Jr, P. H. (2007). Human values, ethics, and design. In The human-computer interaction handbook (pp. 1267-1292). CRC press. Fu, D. Y., & Hughey, J. J. (2019). Releasing a preprint is associated with more attention and citations for the peer-reviewed article. ELife, 8, e52646. Gable, G. G. (2020). Viewpoint: Information systems research strategy. The Journal of Strategic Information Systems, 29(2), 101620. Gasser, U., & Almeida, V. A. F. (2017). A layered model for AI governance. IEEE Internet Computing, 21(6), 58-62. Greaves, H. (2016). Cluelessness. Proceedings of the Aristotelian Society, 116(3), 311-339. Gregor, S., Chandra Kruse, L., & Seidel, S. (2020). The anatomy of a design principle. Journal of the Association for Information Systems, 21(6), 1622-1652. Communications of the Association for Information Systems 610 Volume 50 10.17705/1CAIS.05028 Paper 28 Gregor, S., & Hevner, A. R. (2013). Positioning and presenting design science research for maximum impact. MIS Quarterly, 32(2), 337-355. Gregor, S., & Jones, D. (2007). The anatomy of a design theory. Journal of the Association for Information Systems, 8(5), 312-335. Grossmann, I., Weststrate, N. M., Ardelt, M., Brienza, J. P., Dong, M., Ferrari, M., Fournier, M. A., Hu, C. S., Nusbaum, H. C., & Vervaeke, J. (2020). The science of wisdom in a polarized world: Knowns and unknowns. Psychological Inquiry, 31(2), 103-133. Habermas, J. (1996). Between facts and norms: Contributions to a discourse theory of law and democracy (1st edition). Polity. Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. Minds and Machines, 30(1), 99-120. Herwix, A., & Haj-Bolouri, A. (2021). Revisiting the problem of the problem - An ontology and framework for problem assessment in IS research. In Proceedings of the Twenty-Nineth European Conference on Information Systems (ECIS2021). Herwix, A., & Haj-Bolouri, A. (2020). Having a positive impact with design science research - Learning from effective altruism. In S. Hofmann, O. Müller, & M. Rossi (Eds.), Designing for digital transformation. Co-Creating services with citizens and industry (pp. 235-246). Springer International Publishing. Herwix, A., & Zur Heiden, P. (2022). Context in design science research: Taxonomy and framework. In Proceedings of the 55th Annual Hawaii International Conference on System Sciences. Hevner, A. R., March, S. T., Park, J., & Ram, S. (2004). Design science in information systems research. MIS Quarterly, 28(1), 75-105. Holt, R., & Barnes, C. (2010). Towards an integrated approach to “Design for X”: An agenda for decision- based DFX research. Research in Engineering Design, 21(2), 123-136. Hudson, R. (2016). Why we should not reject the value-free ideal of science. Perspectives on Science, 24(2), 167-191. Hursthouse, R., & Pettigrove, G. (2018). Virtue ethics. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Winter 2018). Metaphysics Research Lab, Stanford University. Jirotka, M., Grimpe, B., Stahl, B. C., Eden, G., & Hartswood, M. (2017). Responsible research and innovation in the digital age. Communications of the ACM, 60(5), 62-68. Kazim, E., & Koshiyama, A. S. (2021). A high-level overview of AI ethics. Patterns, 2(9). Lindgreen, A., & Swaen, V. (2010). Corporate social responsibility. International Journal of Management Reviews, 12(1), 1-7. MacAskill, W. (2015). Doing good better: Effective altruism and a radical new way to make a difference. Guardian Faber Publishing. MacAskill, W., Bykvist, K., & Ord, T. (2020). Moral uncertainty. Oxford University Press. Retrieved from https://www.moraluncertainty.com/ Maedche, A. (2017). Interview with Prof. Jeroen van den Hoven on 'Why do Ethics and Values Matter in Business and Information Systems Engineering?' Business & Information Systems Engineering, 59(4), 297-300. Manders-Huits, N. (2011). What values in design? The challenge of incorporating moral values into design. Science and Engineering Ethics, 17(2), 271-287. McNamara, A., Smith, J., & Murphy-Hill, E. (2018). Does ACM’s code of ethics change ethical decision making in software development? In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (pp. 729-733). Mertens, P., & Barbian, D. (2015). Researching “grand challenges”: A “grand challenge.” Business & Information Systems Engineering, 57(6), 391-403. 611 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 Mingers, J., & Walsham, G. (2010). Toward ethical information systems: The contribution of discourse ethics. MIS Quarterly, 34(4), 833-854. Mittelstadt, B. (2019). Principles alone cannot guarantee ethical AI. Nature Machine Intelligence, 1(11), 501-507. Moeini, M., Rahrovani, Y., & Chan, Y. E. (2019). A review of the practical relevance of IS strategy scholarly research. The Journal of Strategic Information Systems, 28(2), 196-217. MORALITY. (n.d.). In Cambridge English dictionary. Retrieved from https://dictionary.cambridge.org/us/dictionary/english/morality Morana, S., vom Brocke, J., Maedche, A., Seidel, S., Adam, M. T. P., Bub, U., Fettke, P., Gau, M., Herwix, A., Mullarkey, M. T., Nguyen, H. D., Sjöström, J., Toreini, P., Wessel, L., & Winter, R. (2018). Tool support for design science research—Towards a software ecosystem: A report from a DESRIST 2017 workshop. Communications of the Association for Information Systems, 43(1), 237-256. Moriarty, J. (2021). Business ethics. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Fall 2021). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/fall2021/entries/ethics-business/ Müller, V. C. (2021). Ethics of artificial intelligence and robotics. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Summer 2021). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/sum2021/entries/ethics-ai/ Mumford, E. (1995). Effective systems design and requirements analysis: The ETHICS approach. Macmillan Education. Myers, M. D., & Venable, J. R. (2014). A set of ethical principles for design science research in information systems. Information & Management, 51(6), 801-809. Newberry, T., & Ord, T. (2021). The parliamentary approach to moral uncertainty (Technical Report #2021-2). Future of Humanity Institute. O’neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Crown. Ord, T. (2020). The precipice: Existential risk and the future of humanity. Hachette Books. Owen, R., Bessant, J., & Heintz, M. (Eds.). (2013). Responsible innovation: Managing the responsible emergence of science and innovation in society (1st ed.). Wiley. Paradice, D., Freeman, D., Hao, J., Lee, J., & Hall, D. (2018). A review of ethical issue considerations in the information systems research literature. Foundations and Trends in Information Systems, 2(2), 117-236. Parks-Leduc, L., Mulligan, L., & Rutherford, M. A. (2021). Can ethics be taught? Examining the impact of distributed ethical training and individual characteristics on ethical decision-making. Academy of Management Learning & Education, 20(1), 30-49. Perrow, C. (2011). Normal accidents: Living with high risk technologies - Updated edition. Princeton University Press. Pitt, J. C. (2000). Thinking about technology: Foundations of the philosophy of technology. Seven Bridges Press. Porra, J. (2001). A dialogue with C. West Churchman. Information Systems Frontiers, 3(1), 19-27. Purao, S. (2013). Truth or dare: The ontology question in design science research. Journal of Database Management (JDM), 24(3), 51-66. Purao, S. (2021). Design science research problems … Where do they come from? In L. Chandra Kruse, S. Seidel, & G. I. Hausvik (Eds.), The next wave of sociotechnical design (pp. 99-111). Springer International Publishing. Purao, S., Murungi, D., & Yates, D. (2021). Deliberative breakdowns in the social representation process: Evidence from reader comments in partisan news sites. ACM Transactions on Social Computing, 4(2), 1-35. Communications of the Association for Information Systems 612 Volume 50 10.17705/1CAIS.05028 Paper 28 Purao, S., & Wu, A. (2013). Towards values-inspired design: The case of citizen-centric services. In ICIS 2013 Proceedings. Rahwan, I., Cebrian, M., Obradovich, N., Bongard, J., Bonnefon, J.-F., Breazeal, C., Crandall, J. W., Christakis, N. A., Couzin, I. D., Jackson, M. O., Jennings, N. R., Kamar, E., Kloumann, I. M., Larochelle, H., Lazer, D., McElreath, R., Mislove, A., Parkes, D. C., Pentland, A. ‘Sandy,’ Roberts, M. E., Shariff, A., Tenenbaum, J. B. & Well-man, M. (2019). Machine behaviour. Nature, 568(7753), 477-486. Rai, A. (2017). Editor’s comments: Avoiding type III errors: Formulating IS research problems that matter. MIS Quarterly, 41(2), iii-vii. Reid, J. (2009). Conducting qualitative research with advanced cancer patients and their families: Ethical considerations. International Journal of Palliative Nursing, 15(1), 30-33. Richerson, P. J., & Christiansen, M. H. (2013). Cultural evolution: Society, technology, language, and religion. MIT Press. Roes, F. (2003). Belief in moralizing gods. Evolution and Human Behavior, 24(2), 126-135. Ronfeldt, D., & Arquilla, J. (2020). Whose story wins: Rise of the Noosphere, Noopolitik, and information age statecraft. RAND Corporation. Ross, C., & Swetlitz, I. (2017). IBM pitched its Watson supercomputer as a revolution in cancer care. It’s nowhere close. STAT. Retrieved from https://www.statnews.com/2017/09/05/watson-ibm-cancer/ Ross-Hellauer, T. (2017). What is open peer review? A systematic review. F1000Research, 6. Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. Sayre-McCord, G. (2014). Metaethics. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Summer 2014). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/sum2014/entries/metaethics/ Sein, M. K., Henfridsson, O., Purao, S., Rossi, M., & Lindgren, R. (2011). Action design research. MIS Quarterly, 35(1), 37-56. Sinapayen, L. (2021, March 18). The mimosa manifesto: A web platform for open collaboration in science. In Beyond static papers: Rethinking how we share scientific understanding in ML - ICLR 2021 workshop. Singer, P. (2011). The expanding circle: Ethics, evolution, and moral progress. Princeton University Press. Singer, P. (2019). Ethics. In Encyclopedia Britannica. Encyclopædia Britannica, inc. Retrieved from https://www.britannica.com/topic/ethics-philosophy Sinnott-Armstrong, W. (2019). Consequentialism. In E. N. Zalta (Ed.), The Stanford encyclopedia of philosophy (Summer 2019). Metaphysics Research Lab, Stanford University. Retrieved from https://plato.stanford.edu/archives/sum2019/entries/consequentialism/ Spindeldreher, K., Schlagwein, D., & Schoder, D. (2020). How is information systems research justified? An analysis of justifications given by authors. In Proceedings of the 53rd Hawaii International Conference on System Sciences. Stahl, B. C. (2011). IT for a better future: How to integrate ethics, politics and innovation. Journal of Information, Communication and Ethics in Society, 9(3), 140-156. Stahl, B. C. (2012a). Responsible research and innovation in information systems. European Journal of Information Systems, 21(3), 207-211. Stahl, B. C. (2012b). Morality, ethics, and reflection: A categorization of normative IS research. Journal of the Association for Information Systems, 13(8), 636-656. Stahl, B. C., Akintoye, S., Fothergill, B. T., Guerrero, M., Knight, W., & Ulnicane, I. (2019). Beyond research ethics: Dialogues in Neuro-ICT research. Frontiers in Human Neuroscience, 13. Stahl, B. C., Heersmink, R., Goujon, P., Flick, C., Van Den Hoven, J., Wakunuma, K., Ikonen, V., & Rader, M. (2010). Identifying the ethics of emerging information and communication technologies: An essay on issues, concepts and method. International Journal Of Technoethics (IJT), 1(4), 20-38. 613 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 Stahl, B. C., Tremblay, M. C., & LeRouge, C. M. (2011). Focus groups and critical social IS research: How the choice of method can promote emancipation of respondents and researchers. European Journal of Information Systems, 20(4), 378-394. Stilgoe, J., Owen, R., & Macnaghten, P. (2013). Developing a framework for responsible innovation. Research Policy, 42(9), 1568-1580. Strickland, E. (2019). IBM Watson, heal thyself: How IBM overpromised and underdelivered on AI health care. IEEE Spectrum, 56(4), 24-31. The National Artificial Intelligence Initiative. (2021). The National Artificial Intelligence Initiative (NAII). National Artificial Intelligence Initiative. Retrieved from https://www.ai.gov/ Tremblay, M. C., Cucciniello, M., Tarricone, R., Porumbescu, G. A., & Desouza, K. C. (2020). Delivering effective care through mobile apps: Findings from a multi-stakeholder design science approach. In S. Hofmann, O. Müller, & M. Rossi (Eds.), Designing for digital transformation. Co-creating ser- vices with citizens and industry (pp. 3-14). Springer International Publishing. Tremblay, M. C., VanderMeer, D., & Beck, R. (2018). The effects of the quantification of faculty productivity: Perspectives from the design science research community. Communications of the Association for Information Systems, 43. Ulrich, W. (2006). Critical pragmatism: A new approach to professional and business ethics. In Interdisciplinary yearbook for business ethics (V. 1, v. 1). Peter Lang Publishing Inc. Ulrich, W., & Reynolds, M. (2010). Critical systems heuristics. In M. Reynolds & S. Holwell (Eds.), Systems approaches to managing change: A practical guide (pp. 243-292). Springer. van de Poel, I. (2016). An ethical framework for evaluating experimental technology. Science and Engineering Ethics, 22(3), 667-686. Van de Poel, I., & Kroes, P. (2014). Can technology embody values? In The moral status of technical arte- facts (pp. 103-124). Springer. Van Den Hoven, J. (2007). ICT and value sensitive design. In P. Goujon, S. Lavelle, P. Duquenoy, K. Kimppa, & V. Laurent (Eds.), The information society: Innovation, legitimacy, ethics and democracy in honor of professor Jacques Berleur S.J. (Vol. 233, pp. 67-72). Springer. Vial, G. (2019). Understanding digital transformation: A review and a research agenda. The Journal of Strategic Information Systems, 28(2), 118-144. Walsham, G. (1996). Ethical theory, codes of ethics and IS practice. Information Systems Journal, 13. Walsham, G. (2012). Are we making a better world with ICTs? Reflections on a future agenda for the IS field. Journal of Information Technology, 27(2), 87-93. Watson, D., & Floridi, L. (2018). Crowdsourced science: Sociotechnical epistemology in the e-research paradigm. Synthese, 195(2), 741-764. Wilson, D. S., & Gowdy, J. M. (2013). Evolution as a general theoretical framework for economics and public policy. Journal of Economic Behavior & Organization, 90, S3-S10. Wilson, D. S., Hayes, S. C., Biglan, A., & Embry, D. D. (2014). Evolving the future: Toward a science of intentional change. Behavioral and Brain Sciences, 37(4), 395-416. Winter, S. J., & Butler, B. S. (2011). Creating bigger problems: Grand challenges as boundary objects and the legitimacy of the information systems field. Journal of Information Technology, 26(2), 99-108. Wright, D. (2011). A framework for the ethical impact assessment of information technology. Ethics and Information Technology, 13(3), 199-226. Zuboff, S. (2015). Big other: Surveillance capitalism and the prospects of an information civilization. Journal of Information Technology, 30(1), 75-89. Communications of the Association for Information Systems 614 Volume 50 10.17705/1CAIS.05028 Paper 28 Appendix A: Value Reporting Value reporting refers to the explicit positioning of papers with regard to the underlying value systems that were used or considered. Thus, the main point of value reporting is to clearly state the main values that the authors want to promote through their work and succinctly justify their work in relation to them. We suggest that this could take the form of a paragraph in the method or discussion section of a paper or even be a separate section in an appendix. In an effort to provide inspiration for the selection of appropriate values, Table A1 lists an overview of eight stakeholder types with associated core values that IS researchers may wish to support with their work. Importantly, we do not claim that this overview is exhaustive or even comprehensive. It merely aims to provide some inspiration that should be seen as a starting point for a more in-depth investigation of potential values that are useful to consider when planning and conducting IS research. Table A1. Example Stakeholder Types and Associated Core Values to Consider for Value Reporting Stakeholder Type Core Value Description Academic Knowledge An academic is interested in advancing knowledge. Practitioner Satisfaction A practitioner is interested in achieving satisfaction with her performance. Individual Wellbeing An individual is interested in personal wellbeing. Organization Value Realization An organization is interested in realizing value for its members. Business Success A business is interested in success within a competitive environment. Government Societal Welfare A government is interested in managing and increasing societal welfare. Civil Society Justice A civil society organization is interested in promoting justice in relation to a particular cause. Future People Sustainability Future people are interested in the long-term sustainability of the human project. Value Reporting Statement: Example 1 (applies to this paper) This paper has been written mainly with the intention of improving the value realization of the IS research community. On a very abstract level we agree with the seminal works on DSR that relevance and rigor are important core values that ought to define IS research (Hevner et al., 2004). In particular, we hold the assumption that if we increase the relevance and rigor of our work that, all else being equal, we improve the value realization of the IS research community. Against this backdrop, we see ethics as an important field of reference that can help to clarify the notion of relevance (i.e., what is important) in a rigorous way (Herwix & Haj-Bolouri, 2021, 2020). Thus, we suggest that promoting a more systematic integration of ethics into IS research and DSR in particular has the potential to advance, both, the relevance as well as the rigor of the IS research community and, therefore improve its value realization. We aim to achieve a more systematic integration of ethics into IS research by advancing the state of knowledge about ethics in relation to IS research. To achieve this goal, we have reviewed the literature on ethics and also engaged a set of senior DSR scholars to reflect about their understanding and professional experience with ethics in the context of their work. We present our results as a discussion of five intersecting perspectives on ethics: philosophy, design, science, IS practice, and the panelists perspectives. We also offer a synthesis in the form of a set of recommendations for the advancement of ethics in IS research. We deem this to be an appropriate approach given an observed lack of engagement with ethics from a holistic and experiential point of view. While our goal is to provide some guidance, we recognize the complexity of the topic of ethics and our limited experience engaging with ethics in its entirety. No contributor to this paper has a professional degree in ethics, yet all of us have substantial experience in engaging with ethical questions related to our professional work. Thus, we claim a contribution to the IS research knowledge base but encourage future work to critique and improve upon our work. Value Reporting Statement: Example 2 (applies to a different paper) The following value reporting statement corresponds to: Purao et al. (2021). Deliberative Breakdowns in the Social Representation Process: Evidence from Reader Comments in Partisan News Sites. ACM Transactions on Social Computing. Vol. 4, Issue 2, pp. 1-35. 615 Ethics in Information Systems and Design Science Research: Five Perspectives Volume 50 10.17705/1CAIS.05028 Paper 28 This paper was written with the intention of exploring the value realization potential of design science research aimed at the problem of dealing with partisan news sites. The authors assume that open, informed, and well-reasoned dialog is a necessary ingredient for a healthy democracy and that substantial value can be realized if dialog can be shaped to exhibit more of these qualities. It is hypothesized that one consequence of the recent popularity of partisan news sites is a fragmentation of dialog across these sites, which may perpetuate increasingly insulated echo chambers. Thus, the authors argue for a need to better understand the discourse amongst the participants at these sites as a precursor to designing innovative solutions that may open up the echo chambers. The authors aim to contribute to this goal by examining how readers at these partisan news sites consume comments contributed by other visitors (in addition to the actual news stories). The work examines stories and reader comments at two partisan news sites (Breitbart and Daily Kos) surrounding a recent case (Alabama senator Roy Moore who was accused of sexual misconduct and eventually lost the seat in a special election). The analysis reveals multiple deliberative breakdowns—rhetorical, epistemological and emotional—that appear in the reader comments on both partisan news sites. These results are interpreted as pointing to important problems that DSR scholars can address by designing solutions that can promote more open, informed and well-reasoned dialog towards a healthy democracy. Communications of the Association for Information Systems 616 Volume 50 10.17705/1CAIS.05028 Paper 28 About the Authors Alexander Herwix is a doctoral candidate in Information Systems at the University of Cologne. In his research he takes a critical pragmatic stance aiming to contribute to the collective problem solving capacity and flourishing of humanity. He is a member of the Association for Information Systems and has published in outlets such as Communications of the Association for Information Systems, European Conference on Information Systems, Hawaii International Conference on System Sciences, and the International Conference on Design Science Research in Information Systems and Technology. Amir Haj-Bolouri is an Associate Professor in Information Systems at University West. His main research encompasses Design Science Research, Philosophy, Theory Development, Ethics, Action Design Research, Virtual Reality, and Work-integrated Learning. He is a member of Association of Information Systems (AIS), IEEE, and has published in outlets such as European Journal of Information Systems, Scandinavian Journal of Information Systems, Journal of Workplace Learning, European Conference on Information Systems, and more. Matti Rossi is a professor of information systems at Aalto University School of Business. He is a past president of the Association for Information Systems and an AIS Fellow. He has been the principal investigator in several major research projects funded by the technological development center of Finland and Academy of Finland. He was the winner of the 2013 Millennium Distinction Award of Technology Academy of Finland for open source and data research. His research papers have appeared in journals such as MIS Quarterly, JAIS, JSIS, and ISJ and he is a past editor in chief of Communications of the Association for Information Systems. Monica Chiarini Tremblay is a Professor of Operations and Information Systems Management at the Raymond A. Mason School of Business, William and Mary. Her research focuses on information systems and business analytics in the healthcare context, and the use of IS and analytics for equity. Her publications appear in MIS Quarterly, Journal of the AIS, Journal of American Medical Informatics, Decision Sciences, Decision Support Systems, European Journal of Information Systems, ACM Journal of Data and Information Quality, and Communications of the Association for Information Systems and is funded by federal, state and foundation grants. She holds a Ph.D. in Business from the University of South Florida. Sandeep Purao is a Trustee Professor in the Information and Process Management Group and Associate Director of the Hoffman Center for Business Ethics at Bentley University. He is also a Visiting Professor at Agder University in Norway. His current research focuses on the design and evaluation of digital solutions for complex societal problems. His work has been published in journals such as MIS Quarterly, Information Systems Research, Journal of MIS, ACM Computing Surveys, ACM Transactions, Journal of the Medical Internet Research, and others; and funded by federal agencies, private foundations, and industry consortia. He holds a Ph.D. in Management Information Systems from the University of Wisconsin-Milwaukee. Shirley Gregor is a Professor Emerita at the Australian National University and is also an Honorary Professor at the University of Queensland. Her research interests include artificial intelligence, human- computer interaction and the philosophy of science and technology. Professor Gregor spent a number of years in the computing industry in Australia and the United Kingdom before beginning an academic career. She obtained her Ph.D. in Information Systems from the University of Queensland in 1996. Her research has appeared in outlets including MIS Quarterly, Information Systems Research, Journal of Management Information Systems, Journal of the Association of Information Systems, and European Journal of Information Systems. Copyright © 2022 by the Association for Information Systems. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and full citation on the first page. Copyright for components of this work owned by others than the Association for Information Systems must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists requires prior specific permission and/or fee. Request permission to publish from: AIS Administrative Office, P.O. Box 2712 Atlanta, GA, 30301-2712 Attn: Reprints are via e- mail from publications@aisnet.org.","libVersion":"0.3.2","langs":""}